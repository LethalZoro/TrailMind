{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d1d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/.virtualenvs/pi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press and hold SPACE to record. Release to transcribe. Press ESC to quit.\n",
      "Recording... (holding space)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  What should I pack for my hiking trip up north?\n",
      "\n",
      "[SPEAKING]: Layers, rain gear, sturdy hiking boots, sunscreen, insect repellent, map & compass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Transcription:  can you dare be wild as I do\n",
      "\n",
      "[SPEAKING]: Yes, absolutely.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Transcription:  can you join me work as your friend for my ultimate success note?\n",
      "\n",
      "[SPEAKING]: I canâ€™t.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Transcription:  Hello, this is justing to the speed-to-text model.\n",
      "\n",
      "[SPEAKING]: Okay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Transcription:  this is testing to check the speech to text model.\n",
      "\n",
      "[SPEAKING]: Okay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Transcription:  can you tell me what can we do if we go hiking?\n",
      "\n",
      "[SPEAKING]: Plan routes, pack essentials, enjoy nature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Transcription:  Can you tell me some of the dangers associated with hiking?\n",
      "\n",
      "[SPEAKING]: Falls, dehydration, hypothermia, altitude sickness, wildlife encounters, injuries from equipment, getting lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "Interrupted by user\n",
      "Transcription:  you\n",
      "\n",
      "[SPEAKING]: Okay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing raw data 'stdin' : Signed 16 bit Little Endian, Rate 22050 Hz, Mono\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (holding space)\n",
      "Processing...\n",
      "No audio recorded\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import asyncio\n",
    "import shlex\n",
    "import re\n",
    "import ollama\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from pynput import keyboard as pynput_keyboard\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# Setup audio parameters\n",
    "sample_rate = 16000  # Sample rate expected by Whisper\n",
    "channels = 1\n",
    "dtype = 'float32'\n",
    "\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# Create a queue to store audio chunks\n",
    "audio_queue = queue.Queue()\n",
    "is_recording = False\n",
    "stop_recording = False\n",
    "# Async TTS function using Piper in background\n",
    "async def speak_from_queue(queue):\n",
    "    while True:\n",
    "        sentence = await queue.get()\n",
    "        if sentence is None:\n",
    "            break\n",
    "        print(f\"\\n[SPEAKING]: {sentence}\")\n",
    "        safe_text = shlex.quote(sentence)\n",
    "        command = (\n",
    "            f\"echo {safe_text} | piper --model en_US-lessac-medium.onnx --output-raw | \"\n",
    "            f\"aplay -r 22050 -f S16_LE -t raw -\"\n",
    "        )\n",
    "        subprocess.run(command, shell=True)\n",
    "        queue.task_done()\n",
    "\n",
    "# Main function: stream from Ollama, buffer sentences, and queue them\n",
    "async def stream_and_speak(query):\n",
    "    queue = asyncio.Queue()\n",
    "    speaker_task = asyncio.create_task(speak_from_queue(queue))\n",
    "\n",
    "    response = ollama.generate(\n",
    "        model=\"gemma3:1b\",\n",
    "        prompt=(\n",
    "            f\"You are an outdoor voice assistant. Be precise but short in your answers.\\n\"\n",
    "            f\"Current query: {query}\\n\"\n",
    "            f\"Remember to answer the question without any preamble or introduction.\"\n",
    "        ),\n",
    "        stream=True,\n",
    "        options={\"temperature\": 0.7, \"num_predict\": 100}\n",
    "    )\n",
    "\n",
    "    buffer = \"\"\n",
    "    sentence_endings = re.compile(r'([.!?])')\n",
    "\n",
    "    for chunk in response:\n",
    "        buffer += chunk[\"response\"]\n",
    "        while True:\n",
    "            match = sentence_endings.search(buffer)\n",
    "            if not match:\n",
    "                break\n",
    "            end_idx = match.end()\n",
    "            complete_sentence = buffer[:end_idx].strip()\n",
    "            buffer = buffer[end_idx:]\n",
    "            await queue.put(complete_sentence)\n",
    "\n",
    "    # Speak any leftover text\n",
    "    if buffer.strip():\n",
    "        await queue.put(buffer.strip())\n",
    "\n",
    "    # Signal the speaker to finish\n",
    "    await queue.put(None)\n",
    "    await speaker_task  # Wait for speaker to finish\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This is called for each audio block\"\"\"\n",
    "    if is_recording:\n",
    "        audio_queue.put(indata.copy())\n",
    "        # print(f\"Captured audio chunk of shape {indata.shape}\")\n",
    "\n",
    "def key_monitor():\n",
    "    \"\"\"Monitor space bar and ESC using pynput\"\"\"\n",
    "    global is_recording, stop_recording\n",
    "\n",
    "    def on_press(key):\n",
    "        global is_recording\n",
    "        try:\n",
    "            # Check if key is the space key using pynput's Key.space\n",
    "            if key == pynput_keyboard.Key.ctrl and not is_recording:\n",
    "                is_recording = True\n",
    "                audio_queue.queue.clear()\n",
    "                print(\"Recording... (holding space)\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    def on_release(key):\n",
    "        global is_recording, stop_recording\n",
    "        try:\n",
    "            if key == pynput_keyboard.Key.ctrl and is_recording:\n",
    "                is_recording = False\n",
    "                print(\"Processing...\")\n",
    "                process_audio()\n",
    "        except AttributeError:\n",
    "            if key == pynput_keyboard.Key.esc:\n",
    "                stop_recording = True\n",
    "                is_recording = False\n",
    "                print(\"Stopping...\")\n",
    "                return False  # Stop listener\n",
    "\n",
    "    print(\"Press and hold SPACE to record. Release to transcribe. Press ESC to quit.\")\n",
    "    with pynput_keyboard.Listener(on_press=on_press, on_release=on_release) as listener:\n",
    "        listener.join()\n",
    "\n",
    "def process_audio():\n",
    "    \"\"\"Process collected audio chunks and transcribe\"\"\"\n",
    "    if audio_queue.empty():\n",
    "        print(\"No audio recorded\")\n",
    "        return\n",
    "    \n",
    "    chunks = []\n",
    "    while not audio_queue.empty():\n",
    "        chunks.append(audio_queue.get())\n",
    "    \n",
    "    if not chunks:\n",
    "        return\n",
    "        \n",
    "    audio_data = np.concatenate(chunks, axis=0)\n",
    "    audio_flat = audio_data.flatten()\n",
    "    \n",
    "    input_features = processor(\n",
    "        audio_flat,\n",
    "        sampling_rate=sample_rate,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    predicted_ids = model.generate(input_features)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    asyncio.run(stream_and_speak(transcription))\n",
    "\n",
    "\n",
    "def start_space_bar_transcription():\n",
    "    \"\"\"Start the main transcription loop\"\"\"\n",
    "    global stop_recording, is_recording\n",
    "    \n",
    "    stop_recording = False\n",
    "    is_recording = False\n",
    "    \n",
    "    with sd.InputStream(samplerate=sample_rate, channels=channels, dtype=dtype, callback=audio_callback):\n",
    "        monitor_thread = threading.Thread(target=key_monitor)\n",
    "        monitor_thread.start()\n",
    "        \n",
    "        try:\n",
    "            while not stop_recording:\n",
    "                time.sleep(0.1)\n",
    "        except KeyboardInterrupt:\n",
    "            stop_recording = True\n",
    "            is_recording = False\n",
    "            print(\"Interrupted by user\")\n",
    "        \n",
    "        monitor_thread.join()\n",
    "    \n",
    "    print(\"Transcription stopped\")                     \n",
    "\n",
    "start_space_bar_transcription()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a76dd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
